{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pain Level Detection with Full Body Language Analysis\n",
    "# Real-Time Implementation with YOLOv8 Pose Tracking\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict, deque\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 1. Configuration & Constants\n",
    "# ----------------------------\n",
    "PAIN_LEVELS = {\n",
    "    0: {'name': 'No Pain', 'color': (0, 255, 0), 'threshold': 0.7},\n",
    "    1: {'name': 'Low Pain', 'color': (0, 255, 255), 'threshold': 0.65},\n",
    "    2: {'name': 'Medium Pain', 'color': (0, 165, 255), 'threshold': 0.6},\n",
    "    3: {'name': 'High Pain', 'color': (0, 0, 255), 'threshold': 0.55},\n",
    "    4: {'name': 'Unbearable Pain', 'color': (0, 0, 128), 'threshold': 0.5}\n",
    "}\n",
    "\n",
    "SEQ_LENGTH = 45  # 1.5 seconds at 30 FPS\n",
    "KEYPOINT_INDICES = {\n",
    "    'nose': 0,\n",
    "    'shoulders': [5, 6],    # Left and right shoulders\n",
    "    'hips': [11, 12],       # Left and right hips\n",
    "    'knees': [13, 14],      # Left and right knees\n",
    "    'elbows': [7, 8]        # Left and right elbows\n",
    "}\n",
    "INPUT_SHAPE = (SEQ_LENGTH, 17*3)  # 17 keypoints (x, y, confidence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 2. Initialize YOLOv8 Models\n",
    "# ----------------------------\n",
    "pose_model = YOLO('yolov8n-pose.pt')  # Pose estimation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 3. Pain Detection Model\n",
    "# ----------------------------\n",
    "class PainDetector(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(PainDetector, self).__init__()\n",
    "        self.lstm1 = tf.keras.layers.LSTM(128, return_sequences=True)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(0.3)\n",
    "        self.lstm2 = tf.keras.layers.LSTM(64)\n",
    "        self.dense1 = tf.keras.layers.Dense(64, activation='relu')\n",
    "        self.dropout2 = tf.keras.layers.Dropout(0.4)\n",
    "        self.output_layer = tf.keras.layers.Dense(5, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.lstm1(inputs)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.lstm2(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout2(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "pain_model = PainDetector()\n",
    "pain_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 4. Body Language Feature Extraction\n",
    "# ----------------------------\n",
    "def extract_pain_features(keypoints):\n",
    "    \"\"\"Extract biomechanical features based on described pain characteristics\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # Shoulder tension (Low/Medium Pain)\n",
    "    left_shoulder = keypoints[KEYPOINT_INDICES['shoulders'][0]*3:(KEYPOINT_INDICES['shoulders'][0]*3)+2]\n",
    "    right_shoulder = keypoints[KEYPOINT_INDICES['shoulders'][1]*3:(KEYPOINT_INDICES['shoulders'][1]*3)+2]\n",
    "    shoulder_distance = np.linalg.norm(left_shoulder - right_shoulder)\n",
    "    features.append(shoulder_distance)\n",
    "    \n",
    "    # Hip flexibility (Medium/High Pain)\n",
    "    left_hip = keypoints[KEYPOINT_INDICES['hips'][0]*3:(KEYPOINT_INDICES['hips'][0]*3)+2]\n",
    "    right_hip = keypoints[KEYPOINT_INDICES['hips'][1]*3:(KEYPOINT_INDICES['hips'][1]*3)+2]\n",
    "    hip_angle = np.arctan2(right_hip[1]-left_hip[1], right_hip[0]-left_hip[0])\n",
    "    features.append(hip_angle)\n",
    "    \n",
    "    # Spinal curvature (High/Unbearable Pain)\n",
    "    nose = keypoints[KEYPOINT_INDICES['nose']*3:(KEYPOINT_INDICES['nose']*3)+2]\n",
    "    spine_curvature = np.mean([np.linalg.norm(nose - left_hip), np.linalg.norm(nose - right_hip)])\n",
    "    features.append(spine_curvature)\n",
    "    \n",
    "    # Movement jerkiness (All pain levels)\n",
    "    movement_smoothness = np.mean(np.abs(np.diff(keypoints[::3])))  # X coordinates\n",
    "    features.append(movement_smoothness)\n",
    "    \n",
    "    return np.array(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 5. Real-Time Processing\n",
    "# ----------------------------\n",
    "def analyze_body_language():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    track_history = defaultdict(lambda: {'queue': deque(maxlen=SEQ_LENGTH), 'last_prediction': 0})\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            continue\n",
    "            \n",
    "        # Process frame with YOLOv8\n",
    "        results = pose_model.track(frame, persist=True, verbose=False)\n",
    "        annotated_frame = results[0].plot()\n",
    "        \n",
    "        if results[0].keypoints is not None:\n",
    "            for box_id, kps in enumerate(results[0].keypoints.xy.cpu().numpy()):\n",
    "                # Get tracking ID\n",
    "                track_id = box_id if results[0].boxes.id is None else results[0].boxes.id[box_id].item()\n",
    "                \n",
    "                # Process keypoints\n",
    "                keypoints = kps.flatten()\n",
    "                track_history[track_id]['queue'].append(keypoints)\n",
    "                \n",
    "                # Analyze when buffer full\n",
    "                if len(track_history[track_id]['queue']) == SEQ_LENGTH:\n",
    "                    # Convert to sequence array\n",
    "                    sequence = np.array(track_history[track_id]['queue'])\n",
    "                    \n",
    "                    # Normalize and predict\n",
    "                    sequence_norm = (sequence - np.mean(sequence)) / np.std(sequence)\n",
    "                    prediction = pain_model.predict(np.expand_dims(sequence_norm, 0), verbose=0)[0]\n",
    "                    \n",
    "                    # Store prediction\n",
    "                    track_history[track_id]['last_prediction'] = np.argmax(prediction)\n",
    "                    confidence = np.max(prediction)\n",
    "                    \n",
    "                    # Get pain level info\n",
    "                    pain_info = PAIN_LEVELS[track_history[track_id]['last_prediction']]\n",
    "                    \n",
    "                    # Draw annotations\n",
    "                    text = f\"ID {track_id}: {pain_info['name']} ({confidence:.2f})\"\n",
    "                    cv2.putText(annotated_frame, text, (10, 30 + (box_id * 30),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, pain_info['color'], 2))\n",
    "                    \n",
    "                    # Add warning for high pain levels\n",
    "                    if track_history[track_id]['last_prediction'] >= 3:\n",
    "                        cv2.putText(annotated_frame, \"MEDICAL ATTENTION NEEDED!\", \n",
    "                                   (frame.shape[1]-400, 30 + (box_id * 30)),\n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        \n",
    "        # Display frame with OpenCV\n",
    "        cv2.imshow('Pain Level Detection', annotated_frame)\n",
    "        \n",
    "        # Exit on 'q' press\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Run the System\n",
    "# ----------------------------\n",
    "# Load pre-trained weights (replace with actual trained weights)\n",
    "# pain_model.load_weights('pain_detection_model_weights.h5')\n",
    "\n",
    "# Start real-time analysis\n",
    "analyze_body_language()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pain_recognitonenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
